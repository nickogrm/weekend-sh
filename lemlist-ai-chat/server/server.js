// Serveur Express pour le chat AI lemlist
require('dotenv').config();
const express = require('express');
const cors = require('cors');
const Anthropic = require('@anthropic-ai/sdk');
const path = require('path');

const app = express();
const PORT = process.env.PORT || 3000;

// Middleware
app.use(cors());
app.use(express.json({ limit: '10mb' })); // Limite augmentÃ©e pour le contenu des pages
app.use(express.static(path.join(__dirname, '../public')));

// Initialisation du client Anthropic
const anthropic = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY,
});

// Stockage en mÃ©moire des conversations (pour le prototype)
const conversations = new Map();

// Limite de messages par session
const MESSAGE_LIMIT = 5;

/**
 * Endpoint principal pour le chat
 * POST /api/chat
 */
app.post('/api/chat', async (req, res) => {
  console.log('ğŸ“¨ Nouvelle requÃªte chat reÃ§ue');

  try {
    const { message, pageContent, conversationId, messageCount } = req.body;

    // Validation des paramÃ¨tres
    if (!message || !conversationId) {
      console.log('âŒ ParamÃ¨tres manquants');
      return res.status(400).json({
        error: 'ParamÃ¨tres manquants: message et conversationId sont requis'
      });
    }

    // VÃ©rification de la limite de messages
    const currentCount = messageCount || 0;
    if (currentCount >= MESSAGE_LIMIT) {
      console.log('âš ï¸ Limite de messages atteinte');
      return res.status(429).json({
        error: 'Limite de messages atteinte (5/5)',
        limitReached: true,
        messageCount: MESSAGE_LIMIT
      });
    }

    console.log(`ğŸ’¬ Message ${currentCount + 1}/${MESSAGE_LIMIT} pour conversation ${conversationId}`);

    // RÃ©cupÃ©ration ou crÃ©ation de l'historique de conversation
    if (!conversations.has(conversationId)) {
      conversations.set(conversationId, []);
    }
    const conversationHistory = conversations.get(conversationId);

    // Construction du message utilisateur
    let userMessage = message;

    // Si c'est le premier message, on inclut le contexte de la page
    if (currentCount === 0 && pageContent) {
      console.log('ğŸ“„ Premier message - inclusion du contexte de la page');
      userMessage = `Contexte de la page:\n${pageContent}\n\n---\n\nQuestion de l'utilisateur: ${message}`;
    }

    // Ajout du message Ã  l'historique
    conversationHistory.push({
      role: 'user',
      content: userMessage
    });

    // Appel Ã  l'API Anthropic
    console.log('ğŸ¤– Appel Ã  Claude...');
    const response = await anthropic.messages.create({
      model: 'claude-sonnet-4-20250514',
      max_tokens: 1024,
      system: `Tu es un assistant IA intÃ©grÃ© aux pages lemlist. Tu aides les utilisateurs Ã  comprendre le contenu de la page qu'ils consultent.

RÃ¨gles:
- Sois concis et utile dans tes rÃ©ponses
- RÃ©ponds en franÃ§ais
- Base tes rÃ©ponses sur le contexte de la page fourni
- Si une question sort du contexte de la page, indique-le poliment
- Utilise un ton professionnel mais amical`,
      messages: conversationHistory
    });

    // Extraction de la rÃ©ponse
    const reply = response.content[0].text;
    console.log('âœ… RÃ©ponse reÃ§ue de Claude');

    // Ajout de la rÃ©ponse Ã  l'historique
    conversationHistory.push({
      role: 'assistant',
      content: reply
    });

    // Nouveau compteur de messages
    const newMessageCount = currentCount + 1;
    const limitReached = newMessageCount >= MESSAGE_LIMIT;

    if (limitReached) {
      console.log('âš ï¸ Limite atteinte aprÃ¨s ce message');
    }

    // Envoi de la rÃ©ponse
    res.json({
      reply,
      messageCount: newMessageCount,
      limitReached
    });

  } catch (error) {
    console.error('âŒ Erreur serveur:', error);

    // Gestion des erreurs spÃ©cifiques Anthropic
    if (error.status === 401) {
      return res.status(401).json({
        error: 'ClÃ© API Anthropic invalide. VÃ©rifiez votre fichier .env'
      });
    }

    if (error.status === 429) {
      return res.status(429).json({
        error: 'Trop de requÃªtes. Veuillez rÃ©essayer dans quelques instants.'
      });
    }

    res.status(500).json({
      error: 'Erreur serveur. Veuillez rÃ©essayer.'
    });
  }
});

/**
 * Endpoint pour rÃ©initialiser une conversation
 * POST /api/reset
 */
app.post('/api/reset', (req, res) => {
  const { conversationId } = req.body;

  if (conversationId && conversations.has(conversationId)) {
    conversations.delete(conversationId);
    console.log(`ğŸ”„ Conversation ${conversationId} rÃ©initialisÃ©e`);
  }

  res.json({ success: true });
});

/**
 * Health check
 * GET /api/health
 */
app.get('/api/health', (req, res) => {
  res.json({
    status: 'ok',
    hasApiKey: !!process.env.ANTHROPIC_API_KEY
  });
});

// DÃ©marrage du serveur
app.listen(PORT, () => {
  console.log(`
ğŸš€ Serveur lemlist AI Chat dÃ©marrÃ©!
ğŸ“ URL: http://localhost:${PORT}
ğŸ”‘ API Key configurÃ©e: ${process.env.ANTHROPIC_API_KEY ? 'Oui' : 'Non (vÃ©rifiez .env)'}
  `);
});
